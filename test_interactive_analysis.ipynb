{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive SEM Particle Analysis\n",
    "\n",
    "This notebook demonstrates the **complete interactive workflow** from the original notebook, now using the refactored package.\n",
    "\n",
    "## Features:\n",
    "- ‚úÖ Interactive image selection with progress tracking\n",
    "- ‚úÖ Interactive scale bar detection with sliders\n",
    "- ‚úÖ SAM-based particle segmentation\n",
    "- ‚úÖ **Interactive particle refinement** with:\n",
    "  - Click-to-delete particles\n",
    "  - Click-to-add particles with SAM\n",
    "  - Merge mode for combining particles\n",
    "  - Live SAM refinement with point prompts (+/- clicks)\n",
    "  - Edge clearing with buffer\n",
    "  - Dual-view visualization (original + mask)\n",
    "- ‚úÖ Results management and CSV export\n",
    "\n",
    "## Setup\n",
    "\n",
    "Make sure you have the matplotlib widget backend enabled:\n",
    "```python\n",
    "%matplotlib widget\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable interactive matplotlib\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the refactored package\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the package to path (if not installed)\n",
    "package_path = os.path.join(os.getcwd(), 'sem_particle_analysis')\n",
    "if package_path not in sys.path:\n",
    "    sys.path.insert(0, package_path)\n",
    "\n",
    "from sem_particle_analysis import (\n",
    "    SAMModel,\n",
    "    ScaleDetector,\n",
    "    ParticleSegmenter,\n",
    "    ParticleAnalyzer,\n",
    "    ResultsManager,\n",
    "    InteractiveRefiner  # <-- New interactive refinement class\n",
    ")\n",
    "from sem_particle_analysis.utils import (\n",
    "    load_image,\n",
    "    find_images_in_folder,\n",
    "    visualize_masks,\n",
    "    print_summary\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import hashlib\n",
    "\n",
    "print(\"‚úì Packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SAM_CHECKPOINT = \"/Users/sanjaypradeep/segment-anything/models/sam_vit_h_4b8939.pth\"\n",
    "MODEL_TYPE = \"vit_h\"\n",
    "IMAGE_FOLDER = \"/Users/sanjaypradeep/Downloads/Trial Images\"\n",
    "OUTPUT_CSV = \"interactive_analysis_results.csv\"\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  SAM Model: {MODEL_TYPE}\")\n",
    "print(f\"  Image folder: {IMAGE_FOLDER}\")\n",
    "print(f\"  Output CSV: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize SAM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SAM model (do this once)\n",
    "print(\"Loading SAM model...\")\n",
    "sam_model = SAMModel(SAM_CHECKPOINT, model_type=MODEL_TYPE)\n",
    "print(\"‚úì SAM model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize components\n",
    "scale_detector = ScaleDetector(use_gpu=False)\n",
    "segmenter = ParticleSegmenter(sam_model)\n",
    "results_manager = ResultsManager(OUTPUT_CSV)\n",
    "\n",
    "print(\"‚úì All components initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Interactive Image Selection\n",
    "\n",
    "Browse through images with:\n",
    "- **Proceed**: Continue with current image\n",
    "- **Skip**: Move to next image\n",
    "- **Jump**: Go to specific image number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all images\n",
    "image_paths = find_images_in_folder(IMAGE_FOLDER)\n",
    "print(f\"Found {len(image_paths)} images\")\n",
    "\n",
    "# Image selection state\n",
    "current_idx = -1\n",
    "seen_hashes = set()\n",
    "total_images = len(image_paths)\n",
    "current_image = None\n",
    "current_image_path = None\n",
    "\n",
    "# Create UI widgets\n",
    "progress_bar = widgets.IntProgress(value=0, min=0, max=total_images, description='Progress:')\n",
    "progress_label = widgets.Label(value=f\"0/{total_images} (0.0%)\")\n",
    "image_output = widgets.Output()\n",
    "\n",
    "btn_proceed = widgets.Button(description=\"Proceed\", button_style='success')\n",
    "btn_skip = widgets.Button(description=\"Skip\", button_style='warning')\n",
    "jump_input = widgets.IntText(value=1, min=1, max=total_images, description='Jump to #:')\n",
    "btn_jump = widgets.Button(description=\"Jump\", button_style='info')\n",
    "\n",
    "def update_progress():\n",
    "    done = min(current_idx + 1, total_images)\n",
    "    progress_bar.value = done\n",
    "    pct = (done / total_images) * 100 if total_images else 0\n",
    "    progress_label.value = f\"{done}/{total_images} ({pct:.1f}%)\"\n",
    "\n",
    "def load_image_by_index(target_idx):\n",
    "    global current_idx, current_image, current_image_path\n",
    "    \n",
    "    if target_idx < 0 or target_idx >= total_images:\n",
    "        with image_output:\n",
    "            clear_output()\n",
    "            print(f\"Invalid index. Choose between 1 and {total_images}\")\n",
    "        return False\n",
    "    \n",
    "    current_idx = target_idx\n",
    "    update_progress()\n",
    "    \n",
    "    current_image_path = image_paths[current_idx]\n",
    "    current_image = load_image(current_image_path)\n",
    "    img_hash = hashlib.md5(current_image.tobytes()).hexdigest()\n",
    "    \n",
    "    with image_output:\n",
    "        clear_output(wait=True)\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ax.imshow(current_image)\n",
    "        ax.set_title(f\"{os.path.basename(current_image_path)} (#{current_idx + 1}/{total_images})\")\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        if img_hash in seen_hashes:\n",
    "            print(\"‚ö†Ô∏è  Duplicate image (seen before)\")\n",
    "        else:\n",
    "            print(\"‚úì New image ready for analysis\")\n",
    "        print(f\"Dimensions: {current_image.shape[1]} x {current_image.shape[0]} pixels\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def load_next():\n",
    "    global current_idx\n",
    "    while True:\n",
    "        current_idx += 1\n",
    "        if current_idx >= total_images:\n",
    "            with image_output:\n",
    "                clear_output()\n",
    "                print(\"‚úì All images processed!\")\n",
    "            btn_proceed.disabled = True\n",
    "            btn_skip.disabled = True\n",
    "            btn_jump.disabled = True\n",
    "            return\n",
    "        if load_image_by_index(current_idx):\n",
    "            break\n",
    "\n",
    "def on_proceed(b):\n",
    "    img_hash = hashlib.md5(current_image.tobytes()).hexdigest()\n",
    "    seen_hashes.add(img_hash)\n",
    "    with image_output:\n",
    "        print(f\"\\n‚úì PROCEEDING with: {os.path.basename(current_image_path)}\")\n",
    "        print(\"Continue to the next cell for scale bar detection.\")\n",
    "    btn_proceed.disabled = True\n",
    "    btn_skip.disabled = True\n",
    "    btn_jump.disabled = True\n",
    "\n",
    "def on_skip(b):\n",
    "    img_hash = hashlib.md5(current_image.tobytes()).hexdigest()\n",
    "    seen_hashes.add(img_hash)\n",
    "    load_next()\n",
    "\n",
    "def on_jump(b):\n",
    "    target = jump_input.value - 1\n",
    "    if load_image_by_index(target):\n",
    "        jump_input.value = current_idx + 1\n",
    "\n",
    "# Connect events\n",
    "btn_proceed.on_click(on_proceed)\n",
    "btn_skip.on_click(on_skip)\n",
    "btn_jump.on_click(on_jump)\n",
    "\n",
    "# Display UI\n",
    "display(widgets.VBox([\n",
    "    progress_bar,\n",
    "    progress_label,\n",
    "    widgets.HBox([jump_input, btn_jump]),\n",
    "    image_output,\n",
    "    widgets.HBox([btn_proceed, btn_skip])\n",
    "]))\n",
    "\n",
    "# Load first image\n",
    "load_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Interactive Scale Bar Detection\n",
    "\n",
    "Adjust sliders to position the detection region, then click **Detect Scale Bar**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale bar detection with interactive controls\n",
    "if current_image is None:\n",
    "    print(\"ERROR: No image loaded. Please run the previous cell first.\")\n",
    "else:\n",
    "    print(f\"Processing scale bar for: {os.path.basename(current_image_path)}\")\n",
    "    \n",
    "    # Create interactive sliders\n",
    "    width_slider = widgets.FloatSlider(value=0.5, min=0.1, max=1.0, step=0.05, description='Region Width:')\n",
    "    height_slider = widgets.FloatSlider(value=0.06, min=0.02, max=0.2, step=0.01, description='Region Height:')\n",
    "    offset_slider = widgets.FloatSlider(value=0.0, min=0.0, max=0.3, step=0.02, description='Vertical Offset:')\n",
    "    threshold_slider = widgets.IntSlider(value=250, min=100, max=255, step=10, description='Threshold:')\n",
    "    crop_slider = widgets.FloatSlider(value=7.0, min=0.0, max=20.0, step=1.0, description='Bottom Crop %:')\n",
    "    \n",
    "    btn_detect = widgets.Button(description=\"Detect Scale Bar\", button_style='primary')\n",
    "    btn_accept = widgets.Button(description=\"Accept & Continue\", button_style='success', disabled=True)\n",
    "    btn_manual = widgets.Button(description=\"Manual Entry\", button_style='warning')\n",
    "    \n",
    "    detection_output = widgets.Output()\n",
    "    status_output = widgets.Output()\n",
    "    \n",
    "    scale_info = None\n",
    "    cropped_image = None\n",
    "    \n",
    "    def detect_scale():\n",
    "        global scale_info\n",
    "        try:\n",
    "            with status_output:\n",
    "                clear_output()\n",
    "                print(\"Detecting scale bar...\")\n",
    "            \n",
    "            scale_info = scale_detector.detect_scale_bar(\n",
    "                current_image,\n",
    "                region_width=width_slider.value,\n",
    "                region_height=height_slider.value,\n",
    "                vertical_offset=offset_slider.value,\n",
    "                threshold=int(threshold_slider.value)\n",
    "            )\n",
    "            \n",
    "            with detection_output:\n",
    "                clear_output(wait=True)\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                \n",
    "                # Full image with region\n",
    "                axes[0].imshow(current_image)\n",
    "                x0, y0, box_w, box_h = scale_info['region']\n",
    "                rect = plt.Rectangle((x0, y0), box_w, box_h, fill=False, edgecolor='red', linewidth=2)\n",
    "                axes[0].add_patch(rect)\n",
    "                axes[0].set_title(\"Full Image with Scale Bar Region\")\n",
    "                axes[0].axis('off')\n",
    "                \n",
    "                # Detection region\n",
    "                axes[1].imshow(scale_info['binary_image'], cmap='gray', vmin=0, vmax=255)\n",
    "                left, right, y_line = scale_info['line_coords']\n",
    "                axes[1].plot([left, right], [y_line, y_line], 'r-', linewidth=3)\n",
    "                axes[1].text(right + 5, y_line, f\"{scale_info['pixel_length']} px\", color='red', fontsize=12, fontweight='bold', va='center')\n",
    "                axes[1].text(5, 15, f\"OCR: {scale_info['ocr_text']}\", color='yellow', fontsize=10, bbox=dict(facecolor='black', alpha=0.7, pad=4))\n",
    "                axes[1].set_title(f\"Scale Bar Detection (Threshold: {scale_info['threshold']})\")\n",
    "                axes[1].axis('off')\n",
    "                \n",
    "                # Cropped preview\n",
    "                crop_height = int(current_image.shape[0] * (1 - crop_slider.value / 100))\n",
    "                preview = current_image[:crop_height, :]\n",
    "                axes[2].imshow(preview)\n",
    "                axes[2].set_title(f\"Analysis Image (Bottom {crop_slider.value:.1f}% Removed)\")\n",
    "                axes[2].axis('off')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                print(\"SCALE BAR DETECTION RESULTS:\")\n",
    "                print(f\"  Pixel length: {scale_info['pixel_length']} pixels\")\n",
    "                print(f\"  Physical length: {scale_info['scale_nm']:.1f} nm\")\n",
    "                print(f\"  Conversion factor: {scale_info['conversion']:.3f} nm/pixel\")\n",
    "            \n",
    "            with status_output:\n",
    "                clear_output()\n",
    "                print(\"‚úì Scale bar detected successfully!\")\n",
    "            \n",
    "            btn_accept.disabled = False\n",
    "            \n",
    "        except Exception as e:\n",
    "            with status_output:\n",
    "                clear_output()\n",
    "                print(f\"‚ùå ERROR: {str(e)}\")\n",
    "                print(\"Try adjusting parameters or use Manual Entry.\")\n",
    "            btn_accept.disabled = True\n",
    "    \n",
    "    def accept_scale():\n",
    "        global cropped_image, conversion_factor\n",
    "        conversion_factor = scale_info['conversion']\n",
    "        cropped_image = scale_detector.crop_scale_bar(current_image, crop_percent=crop_slider.value)\n",
    "        \n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            print(\"‚úì SCALE BAR ACCEPTED!\")\n",
    "            print(f\"Conversion: {conversion_factor:.3f} nm/pixel\")\n",
    "            print(\"Ready to proceed to segmentation!\")\n",
    "        \n",
    "        btn_detect.disabled = True\n",
    "        btn_accept.disabled = True\n",
    "        btn_manual.disabled = True\n",
    "    \n",
    "    def manual_entry():\n",
    "        global cropped_image, conversion_factor\n",
    "        \n",
    "        manual_scale = widgets.FloatText(description='Scale (nm):', value=100.0)\n",
    "        manual_pixels = widgets.IntText(description='Length (pixels):', value=50)\n",
    "        btn_set = widgets.Button(description='Set Manual Scale', button_style='success')\n",
    "        \n",
    "        def set_manual(b):\n",
    "            global conversion_factor, cropped_image\n",
    "            conversion_factor = scale_detector.set_manual_scale(manual_scale.value, manual_pixels.value)\n",
    "            cropped_image = scale_detector.crop_scale_bar(current_image, crop_percent=crop_slider.value)\n",
    "            with status_output:\n",
    "                clear_output()\n",
    "                print(\"‚úì MANUAL SCALE SET!\")\n",
    "                print(f\"Conversion: {conversion_factor:.3f} nm/pixel\")\n",
    "        \n",
    "        btn_set.on_click(set_manual)\n",
    "        \n",
    "        with detection_output:\n",
    "            clear_output()\n",
    "            display(widgets.VBox([\n",
    "                widgets.HTML(\"<h4>Manual Scale Bar Entry</h4>\"),\n",
    "                manual_scale,\n",
    "                manual_pixels,\n",
    "                btn_set\n",
    "            ]))\n",
    "    \n",
    "    btn_detect.on_click(lambda b: detect_scale())\n",
    "    btn_accept.on_click(lambda b: accept_scale())\n",
    "    btn_manual.on_click(lambda b: manual_entry())\n",
    "    \n",
    "    # Display interface\n",
    "    display(widgets.VBox([\n",
    "        widgets.HTML(\"<h3>Scale Bar Region Controls</h3>\"),\n",
    "        width_slider,\n",
    "        height_slider,\n",
    "        offset_slider,\n",
    "        threshold_slider,\n",
    "        crop_slider,\n",
    "        widgets.HBox([btn_detect, btn_accept, btn_manual]),\n",
    "        status_output,\n",
    "        detection_output\n",
    "    ]))\n",
    "    \n",
    "    # Run initial detection\n",
    "    detect_scale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: SAM Particle Segmentation\n",
    "\n",
    "Generate multiple mask candidates and select the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment particles with SAM\n",
    "if cropped_image is None:\n",
    "    print(\"ERROR: No cropped image available. Please run scale detection first.\")\n",
    "else:\n",
    "    print(f\"Segmenting particles in cropped image: {cropped_image.shape}\")\n",
    "    \n",
    "    masks, scores = segmenter.segment_image(cropped_image, multimask_output=True)\n",
    "    \n",
    "    # Visualize masks\n",
    "    fig = visualize_masks(cropped_image, masks, scores, figsize=(18, 6))\n",
    "    plt.show()\n",
    "    \n",
    "    # Create mask selector\n",
    "    mask_selector = widgets.Dropdown(\n",
    "        options=[(f\"Mask {i} (score: {scores[i]:.3f})\", i) for i in range(len(masks))],\n",
    "        value=int(np.argmax(scores)),\n",
    "        description='Select Mask:'\n",
    "    )\n",
    "    \n",
    "    confirm_button = widgets.Button(description='Confirm Selection', button_style='success')\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    selected_mask = None\n",
    "    \n",
    "    def on_confirm(b):\n",
    "        global selected_mask\n",
    "        selected_mask = segmenter.select_mask(mask_selector.value)\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(f\"‚úì Selected mask {segmenter.selected_mask_index} with score {scores[segmenter.selected_mask_index]:.3f}\")\n",
    "            print(\"Proceed to the next cell for particle analysis and refinement.\")\n",
    "    \n",
    "    confirm_button.on_click(on_confirm)\n",
    "    \n",
    "    display(widgets.VBox([mask_selector, confirm_button, output]))\n",
    "    \n",
    "    # Auto-select best mask\n",
    "    selected_mask = segmenter.select_mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Initial Particle Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze particles\n",
    "if selected_mask is None:\n",
    "    print(\"ERROR: No mask selected. Please run the previous cell.\")\n",
    "else:\n",
    "    # Get binary mask (inverted so particles = 1)\n",
    "    binary_mask = segmenter.get_binary_mask(invert=True)\n",
    "    \n",
    "    # Create analyzer\n",
    "    analyzer = ParticleAnalyzer(conversion_factor=conversion_factor)\n",
    "    \n",
    "    # Analyze mask\n",
    "    num_particles, regions = analyzer.analyze_mask(\n",
    "        binary_mask,\n",
    "        min_area=50,\n",
    "        min_size=30,\n",
    "        remove_border=True,\n",
    "        border_buffer=4\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úì Detected {num_particles} particles\")\n",
    "    \n",
    "    # Get measurements\n",
    "    measurements = analyzer.get_measurements(in_nm=True)\n",
    "    print_summary(measurements, title=\"Initial Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Interactive Particle Refinement\n",
    "\n",
    "### üéØ THIS IS THE KEY INTERACTIVE CELL! üéØ\n",
    "\n",
    "## How to use:\n",
    "\n",
    "### Select/Delete Mode (default):\n",
    "- **Left-click** on a particle to queue it for deletion (turns yellow)\n",
    "- **Right-click** to queue adding a particle at that location\n",
    "- Click **\"Update\"** to apply queued operations\n",
    "- Click **\"Clear queued ops\"** to cancel\n",
    "\n",
    "### Merge Mode:\n",
    "- Toggle **\"Merge mode\"** ON\n",
    "- **Left-click** multiple particles to select for merging (turn cyan)\n",
    "- Click **\"Merge selected\"** to combine them into one particle\n",
    "\n",
    "### SAM Refinement Mode:\n",
    "- Switch to **\"Refine with SAM\"** mode\n",
    "- **Left-click** to add positive points (green +)\n",
    "- **Right-click** to add negative points (red √ó)\n",
    "- SAM will refine the segmentation in real-time\n",
    "- Click **\"Apply SAM to mask\"** when satisfied\n",
    "\n",
    "### Other Controls:\n",
    "- **\"Clear Edges\"** with buffer: Remove particles near borders\n",
    "- **\"Finish\"**: Save current results to CSV\n",
    "\n",
    "### Views:\n",
    "- **Left**: Original image with particle outlines and labels\n",
    "- **Right**: Binary mask (white = particles, black = background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive refiner\n",
    "if analyzer is None or analyzer.mask is None:\n",
    "    print(\"ERROR: No analyzer available. Please run the previous cell.\")\n",
    "else:\n",
    "    # Define callback to save results\n",
    "    def save_results(measurements):\n",
    "        filename = os.path.basename(current_image_path) if current_image_path else \"unknown\"\n",
    "        results_manager.add_result(filename, measurements)\n",
    "        print(f\"\\n‚úì Results saved for '{filename}'\")\n",
    "    \n",
    "    # Create interactive refiner\n",
    "    refiner = InteractiveRefiner(\n",
    "        image=cropped_image,\n",
    "        analyzer=analyzer,\n",
    "        segmenter=segmenter,\n",
    "        results_callback=save_results\n",
    "    )\n",
    "    \n",
    "    # Display the interactive interface\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"INTERACTIVE PARTICLE REFINEMENT\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nInstructions:\")\n",
    "    print(\"  ‚Ä¢ Select/Delete mode: Left-click=delete, Right-click=add\")\n",
    "    print(\"  ‚Ä¢ Merge mode: Left-click particles to merge, then 'Merge selected'\")\n",
    "    print(\"  ‚Ä¢ SAM mode: Left-click=positive (+), Right-click=negative (‚àí)\")\n",
    "    print(\"  ‚Ä¢ Click 'Finish' when done to save results\\n\")\n",
    "    \n",
    "    refiner.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: View Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final measurements after refinement\n",
    "if 'refiner' in locals():\n",
    "    final_measurements = refiner.get_measurements(in_nm=True)\n",
    "    print_summary(final_measurements, title=\"Final Refined Analysis\")\n",
    "    \n",
    "    # Get final mask\n",
    "    final_mask = refiner.get_final_mask()\n",
    "    print(f\"\\nFinal mask shape: {final_mask.shape}\")\n",
    "    print(f\"Total pixels segmented: {final_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: View All Saved Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of all results\n",
    "results_manager.print_summary()\n",
    "\n",
    "# View results dataframe\n",
    "results_df = results_manager.get_results()\n",
    "print(\"\\nResults DataFrame:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Next Image\n",
    "\n",
    "To process the next image, **restart from Step 3** (Image Selection cell) and work through the workflow again.\n",
    "\n",
    "All results are automatically saved to the CSV file!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides the **complete interactive workflow** from the original notebook, now fully refactored and modular:\n",
    "\n",
    "‚úÖ **All original features preserved:**\n",
    "- Interactive image browsing\n",
    "- Adjustable scale bar detection\n",
    "- Multiple SAM mask candidates\n",
    "- Click-to-delete particles\n",
    "- Click-to-add particles\n",
    "- Merge particles\n",
    "- Live SAM refinement with +/‚àí points\n",
    "- Edge clearing\n",
    "- Results management\n",
    "\n",
    "‚úÖ **Benefits of refactored code:**\n",
    "- Clean, reusable API\n",
    "- Modular components\n",
    "- Easy to extend\n",
    "- Properly documented\n",
    "- Can be used in scripts or notebooks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
